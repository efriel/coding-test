"""
OpenAI Service Module

This module provides functionality for interacting with the OpenAI GPT model. 
It sends prompts to the OpenAI API and retrieves responses.

Purpose:
- To integrate with OpenAI's GPT model for generating AI responses.
- To handle errors and provide fallback messages in case of API issues.

Dependencies:
- The `openai` library is used to interact with OpenAI's API.
- The `settings` module provides the `OPENAI_API_KEY` configuration.

Functions:
- ask_openai: Sends a prompt to the OpenAI GPT model and retrieves the response.

Integration:
- This service is used by the `ai_services.py` module to route prompts to the OpenAI GPT model.
"""

import openai
from config.settings import settings
from openai import OpenAIError

client = openai.OpenAI()

def ask_openai(prompt: str) -> str:
    """
    Sends a prompt to the OpenAI GPT model and retrieves the response.

    Parameters:
    - prompt (str): The input prompt to be processed by the OpenAI GPT model.

    Returns:
    - str: The response generated by the OpenAI GPT model, or a fallback message in case of an error.

    Example Usage:
    >>> response = ask_openai("What is the weather today?")
    >>> print(response)
    """
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except openai.AuthenticationError:
        return "Server authentication failed. (Use other AI model)"
    except openai.RateLimitError:
        return "Rate limit exceeded: Please try again later. (Use other AI model)"
    except openai.APIConnectionError:
        return "API network connection error."
    except openai.OpenAIError as e:
        return f"OpenAI error: {str(e)}"
    except Exception as e:
        return f"Unexpected error: {str(e)}"